{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRACE\n",
    "Script downloads intraday TRACE bond data, calculates daily summary statistics at the bond-day level and creates a dataframe over the specified (mindate,maxdate) sample range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import wrds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize WRDS connection\n",
    "db = wrds.Connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db.list_libraries();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db.list_tables(library='trace');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db.describe_table(library='trace', table='trace');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample query:\n",
    "testdate = datetime.date(2002,6,31)\n",
    "query = str(\"\"\"SELECT cusip_id, bsym, trd_exctn_dt, trd_exctn_tm, rptd_pr\n",
    "        FROM trace.trace\n",
    "        WHERE  trd_exctn_dt < '{!s}'\n",
    "        LIMIT 5000 \"\"\").format(testdate)\n",
    "query\n",
    "dftemp = db.raw_sql(query)\n",
    "\n",
    "dftemp = dftemp.dropna(subset=['cusip_id'])\n",
    "\n",
    "dftemp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function that summarizes data for a given day\n",
    "def get_dfTRACEdailysummary(db, date):\n",
    "    query = str(\"\"\"SELECT cusip_id, bsym, trd_exctn_dt, trd_exctn_tm, rptd_pr\n",
    "        FROM trace.trace\n",
    "        WHERE  trd_exctn_dt = '{!s}' \"\"\").format(date)\n",
    "    \n",
    "    # download data\n",
    "    dftemp = db.raw_sql(query)\n",
    "    \n",
    "    # drop observations with missing cusip\n",
    "    dftemp = dftemp.dropna(subset=['cusip_id'])\n",
    "    \n",
    "    # take last observation from each cusip (i.e. closing price)\n",
    "    # ATTENTION: ASSUMING THAT QUERIED DATA ALREADY SORTED ACROSS EXECUTION TIME!\n",
    "    grouped = dftemp.groupby(['cusip_id'])\n",
    "    dfout = grouped.agg({'bsym':'last', 'rptd_pr':'last', 'trd_exctn_dt':'last',\n",
    "                         'trd_exctn_tm':'last'}).reset_index()\n",
    "    \n",
    "    return dfout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose sample range\n",
    "mindate = datetime.date(2015,7,1)\n",
    "maxdate = datetime.date(2018,6,30)\n",
    "day_1 = datetime.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test for a given day\n",
    "dfTRACEdsum = get_dfTRACEdailysummary(db, mindate)\n",
    "dfTRACEdsum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop over all days\n",
    "i = 0\n",
    "date = mindate\n",
    "print(date)\n",
    "dfTRACEdsum = get_dfTRACEdailysummary(db, mindate)\n",
    "print(dfTRACEdsum.shape)\n",
    "while True:\n",
    "    i = i+1\n",
    "    date = date + day_1\n",
    "    print(date)\n",
    "#     print('iteration {!s}: date is {!s}'.format(i, date))\n",
    "    \n",
    "    # get data from that date\n",
    "    dfTRACEdsum_more = get_dfTRACEdailysummary(db, date)\n",
    "    print(dfTRACEdsum_more.shape)\n",
    "#     print('size of new data is {!s}'.format(dfTRACEdsum_more.size))\n",
    "    \n",
    "    dfTRACEdsum = pd.concat([dfTRACEdsum, dfTRACEdsum_more])\n",
    "    \n",
    "    if date >= maxdate:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTRACEdsum_new = dfTRACEdsum.drop_duplicates(subset=['cusip_id', 'trd_exctn_dt'],\n",
    "                                              keep='last', inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTRACEdsum_new.to_csv('TRACE-2015-2018.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concatenate\n",
    "It can take too much RAM to store the data over a large time sample. An easy approach is to only download a few years at a time, save and then concatenate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('TRACE-2002-2006.csv', delimiter=',')\n",
    "\n",
    "df_add = pd.read_csv('TRACE-2007-2010.csv', delimiter=',')\n",
    "df_all = pd.concat([df_all, df_add])\n",
    "\n",
    "df_add = pd.read_csv('TRACE-2010-2012.csv', delimiter=',')\n",
    "df_all = pd.concat([df_all, df_add])\n",
    "\n",
    "df_add = pd.read_csv('TRACE-2012-2015.csv', delimiter=',')\n",
    "df_all = pd.concat([df_all, df_add])\n",
    "\n",
    "df_add = pd.read_csv('TRACE-2015-2018.csv', delimiter=',')\n",
    "df_all = pd.concat([df_all, df_add])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all.drop_duplicates(subset=['cusip_id', 'trd_exctn_dt'], keep='last', inplace=True)\n",
    "df_all.to_csv('TRACE-all.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
